{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Learned Token Position Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import import_ipynb # using this to import the modules notebook\n",
    "import modules # importing the notebook\n",
    "import tensorflow as tf\n",
    "from tensorboard.plugins import projector\n",
    "import os\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse Transformer Behavior\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Model Configuration (from train_model.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_tokens: the number of different tokens in the corpus\n",
    "# t: the length of the sequences as input to the model\n",
    "# depth: depth of the network (number of transformer blocks)\n",
    "# heads: number of attention heads in the multi-head attention mechanism\n",
    "# k: embedding dimension (needs to be a multiple of heads)\n",
    "\n",
    "k = 6 # x * heads\n",
    "num_tokens = 10 # integers from 0 to 9\n",
    "heads = 3\n",
    "depth = 2\n",
    "t = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hasattr(modules, 'GTransformer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained model\n",
    "model = modules.GTransformer(k=k, heads=heads, depth=depth, t=t, num_tokens=num_tokens)\n",
    "model.load_state_dict(torch.load('gtransformer.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze Token Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set token\n",
    "tokens = np.arange(num_tokens)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create logging directory\n",
    "log_dir='./torchlogs/pos-tokens/'\n",
    "\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the token embeddings\n",
    "pos_embeddings = model.pos_embedding.weight.data.cpu().numpy()\n",
    "print(pos_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TensorFlow variable for the embeddings\n",
    "embeddings = tf.Variable(pos_embeddings, name='pos_embeddings')\n",
    "\n",
    "# Save the embeddings and metadata\n",
    "checkpoint = tf.train.Checkpoint(embedding=embeddings)\n",
    "checkpoint.save(os.path.join(log_dir, \"token_embedding.ckpt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up config.\n",
    "config = projector.ProjectorConfig()\n",
    "embedding = config.embeddings.add()\n",
    "\n",
    "# The name of the tensor will be suffixed by `/.ATTRIBUTES/VARIABLE_VALUE`.\n",
    "embedding.tensor_name = \"embedding/.ATTRIBUTES/VARIABLE_VALUE\"\n",
    "embedding.metadata_path = 'metadata.tsv'\n",
    "projector.visualize_embeddings(log_dir, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write metadata (sentences)\n",
    "with open(os.path.join(log_dir, 'metadata.tsv'), 'w') as f:\n",
    "    for token in tokens:\n",
    "        f.write(f\"{token}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start TensorBoard (or use the command line: tensorboard --logdir=./src/model-basic/torchlogs/pos-tokens/)\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./torchlogs/vocab-tokens/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
